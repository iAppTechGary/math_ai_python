from django.conf import settingsfrom rest_framework.views import APIViewfrom rest_framework.response import Responsefrom rest_framework import status, parsersfrom rest_framework.authentication import BaseAuthentication, TokenAuthenticationfrom rest_framework.permissions import IsAuthenticatedfrom rest_framework.exceptions import AuthenticationFailedfrom django.http import HttpResponse, StreamingHttpResponsefrom .models import AppUser, MathQuery from .serializers import AppUserSerializerfrom django.shortcuts import renderfrom .utils import log_user_searchimport docx2txtimport tempfileimport fitzimport timefrom openai import OpenAIimport base64import uuidimport os,ioimport threading,jsonimport pytesseractfrom PIL import Imagefrom io import BytesIOimport pytesseractimport mimetypes import speech_recognition as srfrom pydub import AudioSegmentfrom opik.integrations.openai import track_openaios.environ["OPENAI_API_KEY"] =  settings.OPENAI_API_KEYos.environ["OPIK_PROJECT_NAME"] = "math_ai_live"  openai_client = OpenAI()openai_client = track_openai(openai_client)class TokenAuth(BaseAuthentication):    def authenticate(self, request):        auth_header = request.headers.get("Authorization")                if not auth_header or not auth_header.startswith("Bearer "):            return None                token = auth_header.split(" ")[1]                try:            user = AppUser.objects.get(token=token)        except AppUser.DoesNotExist:            raise AuthenticationFailed("Invalid or expired token.")                return (user, None)         class registerUser(APIView):    def post(self, request):        udid = request.data.get("udid")        if not udid:            return Response({"error": "UDID is required."}, status=status.HTTP_400_BAD_REQUEST)        user, created = AppUser.objects.get_or_create(udid=udid)        serializer = AppUserSerializer(user, data=request.data, partial=True)        if serializer.is_valid():            serializer.save()        else:            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)        user.token = str(uuid.uuid4())        user.save()        message = "New user registered successfully." if created else "Existing user retrieved successfully."        return Response({            "message": message,            "user_id": user.id,            "token": f"Bearer {user.token}"        }, status=status.HTTP_200_OK)class solveMathProblem(APIView):    authentication_classes = [TokenAuth]    parser_classes = [parsers.MultiPartParser, parsers.FormParser, parsers.JSONParser]    def post(self, request):        user = request.user        question = request.data.get("question", "").strip()        image = request.FILES.get("file")        prompt = request.data.get("prompt", "").strip()        if not question and not image:            return Response({"error": "Please provide a math question or an image."}, status=status.HTTP_400_BAD_REQUEST)                                default_prompt = "You are a helpful assistant that solves math problems clearly, step-by-step."        system_prompt = prompt if prompt else default_prompt        try:            # Case 1: Image-based math solving            if image:                image_bytes = image.read()                base64_image = base64.b64encode(image_bytes).decode('utf-8')                gpt_model = "gpt-4o"                messages=[                        {                            "role": "system",                            "content": system_prompt                        },                        {                            "role": "user",                            "content": [                                {"type": "text", "text": "Solve this math problem step-by-step:"},                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}                            ]                        }                    ]                               response = openai_client.chat.completions.create(                    model=gpt_model,                    stream=True,                    temperature=0.7,                    max_tokens=4096,                    top_p=0.8,                    frequency_penalty=0.0,                    presence_penalty=0.0,                    messages=messages                )                def event_stream():                    full_answer = []                    for chunk in response:                        chunk_dict = chunk.model_dump()                        content = chunk_dict.get("choices", [{}])[0].get("delta", {}).get("content")                        if content:                            full_answer.append(content)                            yield f"data: {json.dumps({'content': content})}\n\n"                                       log_user_search(user=user, input_type="image", prompt=base64_image, response="".join(full_answer).strip())                http = StreamingHttpResponse(event_stream(), content_type='text/event-stream')                http['Cache-Control'] = 'no-cache'                return http            # Case 2: Text-based math solving            else:                # TEXT CASE                gpt_model = "gpt-3.5-turbo"                messages = [                    {"role": "system", "content":system_prompt},                    {"role": "user", "content": f"Solve this step-by-step: {question}"}                ]                response = openai_client.chat.completions.create(                    model=gpt_model,                    stream=True,                    temperature=0.7,                    max_tokens=4096,                    top_p=0.8,                    frequency_penalty=0.0,                    presence_penalty=0.0,                    messages=messages                )                def event_stream():                    full_answer = []                    for chunk in response:                        chunk_dict = chunk.model_dump()                        content = chunk_dict.get("choices", [{}])[0].get("delta", {}).get("content")                        if content:                            full_answer.append(content)                            yield f"data: {json.dumps({'content': content})}\n\n"                                                         #log_user_search(user=user, input_type="text", prompt=question, response="".join(full_answer).strip())                http = StreamingHttpResponse(event_stream(), content_type='text/event-stream')                http['Cache-Control'] = 'no-cache'                return http        except Exception as e:            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)class pdfSummaryAnalysis(APIView):    authentication_classes = [TokenAuth]    parser_classes = [parsers.MultiPartParser, parsers.FormParser, parsers.JSONParser]    def post(self, request):        file_obj = request.FILES.get("file")        if not file_obj:            return Response({"error": "No file provided."}, status=status.HTTP_400_BAD_REQUEST)        try:            prompt = (                "Read and deeply analyze the attached PDF. Provide a clear, concise, and well-structured summary "                "that captures the main ideas, key points, and any important details from the text. "                "If the PDF contains any images, diagrams, or charts, analyze their content as well and incorporate relevant insights into the summary. "                "Focus only on meaningful content and ignore formatting or metadata. Write in plain, professional English so the reader can quickly grasp the full context without reading the entire document."            )            # Convert uploaded file to stream            file_bytes = file_obj.read()            file_stream = io.BytesIO(file_bytes)            file_stream.seek(0)            # Upload file to OpenAI            uploaded_file = openai_client.files.create(                file=(file_obj.name, file_stream),                purpose="user_data"            )            # Run completion using gpt-4o            completion = openai_client.chat.completions.create(                model="gpt-4o",                messages=[                    {                        "role": "user",                        "content": [                            {                                "type": "file",                                "file": {"file_id": uploaded_file.id}                            },                            {                                "type": "text",                                "text": prompt                            }                        ]                    }                ]            )            answer = completion.choices[0].message.content            return Response({"result": answer})        except Exception as e:            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)# === COMMON BASE CLASS ===class BaseStreamAPIView(APIView):    def extract_text_from_docx(self, file_obj):        try:            print(f"Extracting text from DOC/DOCX file: {file_obj.name}")            # Save uploaded file temporarily            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")            for chunk in file_obj.chunks():                temp_file.write(chunk)            temp_file.close()            # Use docx2txt to extract text            text = docx2txt.process(temp_file.name)            print(f"Extracted text length: {len(text)} characters")            return text.strip()        except Exception as e:            print(f"DOCX text extraction error: {e}")            return ""    def stream_docx_summary(self, file_obj, user, custom_prompt=None):        def event_stream():            full_response = ""            prompt_prefix = custom_prompt or (                "Read and deeply analyze the following document text. Provide a clear, concise, and well-structured summary "                "that captures the main ideas, key points, and any important details from the text. "                "Focus only on meaningful content and ignore formatting or metadata. Write in plain, professional English."            )            # Extract text from DOCX            doc_text = self.extract_text_from_docx(file_obj)            if not doc_text:                yield f"data: {json.dumps({'error': 'Could not extract text from the provided DOC/DOCX document.'})}\n\n"                yield "data: [DONE]\n\n"                return            # Combine into a prompt            final_prompt = f"{prompt_prefix}\n\nDocument Text:\n{doc_text}"            response = openai_client.chat.completions.create(                model="gpt-4o",                messages=[                    {"role": "user", "content": final_prompt}                ],                stream=True            )            for chunk in response:                for choice in chunk.choices:                    content = getattr(choice.delta, "content", None)                    if content:                        full_response += content                        yield f"data: {json.dumps({'content': content})}\n\n"            log_user_search(user=user, input_type="docx", prompt=final_prompt, response=full_response)            yield "data: [DONE]\n\n"        return event_stream()    def stream_pdf_summary(self, file_obj, user, custom_prompt=None):        def event_stream():            full_response = ""            prompt = custom_prompt or (                "Read and deeply analyze the attached PDF. Provide a clear, concise, and well-structured summary "                "that captures the main ideas, key points, and any important details from the text. "                "If the PDF contains any images, diagrams, or charts, analyze their content as well and incorporate relevant insights into the summary. "                "Focus only on meaningful content and ignore formatting or metadata. Write in plain, professional English."            )            file_bytes = file_obj.read()            file_stream = io.BytesIO(file_bytes)            file_stream.seek(0)            uploaded_file = openai_client.files.create(                file=(file_obj.name, file_stream),                purpose="user_data"            )            response = openai_client.chat.completions.create(                model="gpt-4o",                messages=[                    {                        "role": "user",                        "content": [                            {"type": "file", "file": {"file_id": uploaded_file.id}},                            {"type": "text", "text": prompt}                        ]                    }                ],                stream=True            )            for chunk in response:                for choice in chunk.choices:                    content = getattr(choice.delta, "content", None)                    if content:                        full_response += content                        yield f"data: {json.dumps({'content': content})}\n\n"            log_user_search(user=user, input_type="pdf", prompt=prompt, response=full_response)            yield "data: [DONE]\n\n"        return event_stream()    def stream_image_summary(self, file_obj, user, custom_prompt=None):        def event_stream():            full_response = ""            prompt = custom_prompt or (                "Analyze the content of the image and summarize any visible text, scenes, or important information. "                "Focus on relevant, meaningful details. Write in professional English."            )            image_bytes = file_obj.read()            image_b64 = base64.b64encode(image_bytes).decode("utf-8")            mime_type = mimetypes.guess_type(file_obj.name)[0] or "image/png"            data_uri = f"data:{mime_type};base64,{image_b64}"            response = openai_client.chat.completions.create(                model="gpt-4o",                messages=[                    {                        "role": "user",                        "content": [                            {"type": "image_url", "image_url": {"url": data_uri}},                            {"type": "text", "text": prompt}                        ]                    }                ],                stream=True            )            for chunk in response:                for choice in chunk.choices:                    content = getattr(choice.delta, "content", None)                    if content:                        full_response += content                        yield f"data: {json.dumps({'content': content})}\n\n"            log_user_search(user=user, input_type="image", prompt=prompt, response=full_response)            yield "data: [DONE]\n\n"        return event_stream()    def stream_chat_completion(self, user_prompt, user):        def event_stream():            full_response = ""            response = openai_client.chat.completions.create(                model="gpt-4o",                messages=[                    {"role": "user", "content": user_prompt}                ],                stream=True            )            for chunk in response:                for choice in chunk.choices:                    content = getattr(choice.delta, "content", None)                    if content:                        full_response += content                        yield f"data: {json.dumps({'content': content})}\n\n"            log_user_search(user=user, input_type="text", prompt=user_prompt, response=full_response)            yield "data: [DONE]\n\n"        return event_stream()      def extract_text_from_audio(self, audio_file):        try:            print(f"Uploading audio file to OpenAI for transcription: {audio_file.name}")            # Read file content as bytes            file_bytes = audio_file.read()            # Wrap in a BytesIO stream ? OpenAI accepts this            file_stream = io.BytesIO(file_bytes)            file_stream.name = audio_file.name  # Set filename so OpenAI knows the type (important!)            response = openai_client.audio.transcriptions.create(                model="whisper-1",                file=file_stream,  # Now this is correct!                response_format="text",                language="en"  # Change to "pa" for Punjabi, "hi" for Hindi if needed            )            print(f"Transcribed text: {response}")            return response.strip()        except Exception as e:            print(f"Audio transcription error (OpenAI Whisper): {e}")            return ""class pdfSummaryAPIView(BaseStreamAPIView):    authentication_classes = [TokenAuth]    parser_classes = [parsers.MultiPartParser, parsers.FormParser, parsers.JSONParser]    def post(self, request):        user = request.user        file_obj = request.FILES.get("file")        prompt = request.FILES.get("prompt")        if not file_obj:            return Response({"error": "No file provided."}, status=status.HTTP_400_BAD_REQUEST)        try:            mime_type, _ = mimetypes.guess_type(file_obj.name)            if mime_type and mime_type.startswith("image/"):                return StreamingHttpResponse(                    self.stream_image_summary(file_obj, user, prompt),                    content_type="text/event-stream"                )            elif mime_type == "application/pdf":                return StreamingHttpResponse(                    self.stream_pdf_summary(file_obj, user, prompt),                    content_type="text/event-stream"                )            else:                return Response({"error": "Unsupported file type."}, status=status.HTTP_400_BAD_REQUEST)        except Exception as e:            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)                        class chatCompletionAPIView(BaseStreamAPIView):    authentication_classes = [TokenAuth]    parser_classes = [parsers.MultiPartParser, parsers.FormParser, parsers.JSONParser]    def post(self, request):        user = request.user        prompt_text = request.data.get("prompt", "").strip()        file_obj = request.FILES.get("file")        audio_file = request.FILES.get("audio")        if not prompt_text and not file_obj and not audio_file:            return Response({"error": "Please provide at least a prompt, document/image, or audio."},                            status=status.HTTP_400_BAD_REQUEST)        try:            if audio_file:                audio_text = self.extract_text_from_audio(audio_file)                if not audio_text:                    return Response({"error": "Could not extract text from the provided audio."},                                    status=status.HTTP_400_BAD_REQUEST)                combined_prompt = ""                if prompt_text:                    combined_prompt += f"User Prompt:\n{prompt_text}\n\n"                combined_prompt += f"Extracted from Audio:\n{audio_text}\n\n"                return StreamingHttpResponse(                    self.stream_chat_completion(combined_prompt, user),                    content_type="text/event-stream"                )            elif file_obj:                mime_type, _ = mimetypes.guess_type(file_obj.name)                if mime_type and mime_type.startswith("image/"):                    return StreamingHttpResponse(                        self.stream_image_summary(file_obj, user, prompt_text),                        content_type="text/event-stream"                    )                elif mime_type in ["application/vnd.openxmlformats-officedocument.wordprocessingml.document","application/msword" ]:                    return StreamingHttpResponse(                        self.stream_docx_summary(file_obj, user, prompt_text),                        content_type="text/event-stream"                    )                elif mime_type == "application/pdf":                    return StreamingHttpResponse(                        self.stream_pdf_summary(file_obj, user, prompt_text),                        content_type="text/event-stream"                    )                else:                    return Response({"error": "Unsupported file type."}, status=status.HTTP_400_BAD_REQUEST)            elif prompt_text:                return StreamingHttpResponse(                    self.stream_chat_completion(prompt_text, user),                    content_type="text/event-stream"                )        except Exception as e:            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)                            class TopicCompletionAPIView(BaseStreamAPIView):    authentication_classes = [TokenAuth]    parser_classes = [parsers.JSONParser, parsers.FormParser]    def post(self, request):        user = request.user        topic = request.data.get("topic", "").strip()        niche = request.data.get("niche", "").strip()        style = request.data.get("writing_style", "").strip()        if not topic:            return Response({"error": "Please provide a topic."}, status=status.HTTP_400_BAD_REQUEST)        # Prompt template        prompt = f"Write a comprehensive article on the topic: '{topic}'."        if niche:            prompt += f" The article should be relevant to the niche of '{niche}'."        if style:            prompt += f" Use a '{style}' writing style."        prompt += (            " Make sure the article is engaging, informative, and well-structured. "            "Avoid repetition and filler content. Use professional English."        )        try:            return StreamingHttpResponse(                self.stream_chat_completion(prompt, user),                content_type="text/event-stream"            )        except Exception as e:            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)                        def terms_view(request):    return render(request, 'terms-and-conditions.html')def privacy_view(request):    return render(request, 'privacy-policy.html')